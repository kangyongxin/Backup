#基础版本，可以完成：
从专家数据中进行pretrain
然后用训练的网络初始化DQFD的Q网络
同时用ppo产生与专家数据相似的数据写入记忆中
从记忆中采样不断地更新Q网络
记忆中的数据包含三个部分：demo,ppo generate,q_net generate
用记忆中的数据去训练GAIL，提升PPO的同时提升Q

但是ppo每次都是从零学起，这极大地限制了学习速度，而且有时候会拉低DQN的效果

其它模型不能跑，没有专家数据
20190322

